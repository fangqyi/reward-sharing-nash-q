meta_type: "pq"
p_actor: "pq_agent"
q_actor: "pq_agent"
pq_actor_hidden_sizes: [32]
critic_hidden_sizes: [32]
pq_output_type: "pi_logits"
learner: "pq_q_learner"
runner: "pq_episode"
mac: "shared_pq"
env_steps_every_pq: 4000
max_pq_training_steps: 10000
pq_sample_runs: 400

epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000

buffer_size: 5000

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"

name: "pq_dgn_q_learning"